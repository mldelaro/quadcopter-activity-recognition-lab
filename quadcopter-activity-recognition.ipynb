{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello linear model\n",
    "This tutorial is part of the Tensorflow getting started documentation at: https://www.tensorflow.org/tutorials/wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data into a feature space\n",
    "Extract a features of a sliding window from a given sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting labels for samples in raw data directory:\n",
      "{'rotor3', 'rotor4', 'rotor2', 'rotor1'}\n",
      "Extracting labels for samples in raw data directory:\n",
      "{'rotor3', 'rotor4', 'rotor2', 'rotor1'}\n",
      "Extracting features for: rotor3\n",
      "Extracting features for: rotor4\n",
      "Extracting features for: rotor2\n",
      "Extracting features for: rotor1\n",
      "Extracting features for: rotor3\n",
      "Extracting features for: rotor4\n",
      "Extracting features for: rotor2\n",
      "Extracting features for: rotor1\n"
     ]
    }
   ],
   "source": [
    "#TODO: Change rotor label to the appropriate flight controls\n",
    "import csv\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "FEATURE_DATA_FILEPATH = './data/'\n",
    "\n",
    "feature_csv_columns = ['average', 'median']\n",
    "imu_data_columns = ['gyro_roll', 'gyro_pitch', 'gyro_yaw', 'acc_x', 'acc_y', 'acc_z']\n",
    "\n",
    "def feature_average(data_sample):\n",
    "    fSum = 0;\n",
    "    nIndex = 0;\n",
    "    for data in data_sample:\n",
    "        fSum = fSum + data\n",
    "        nIndex = nIndex + 1\n",
    "    return float(fSum / nIndex)\n",
    "\n",
    "def feature_variance(data_sample):\n",
    "    return np.var(data_sample)\n",
    "\n",
    "def feature_median(data_sample):\n",
    "    return np.median(data_sample, axis=0)\n",
    "\n",
    "feature_calculations = {\n",
    "    'average' : feature_average,\n",
    "    'median' : feature_median\n",
    "}\n",
    "\n",
    "# Read a *.csv file and extract the sliding window\n",
    "import collections\n",
    "def extract_features_from_imu_data_samples_for_label(data_sample_filepath, features_filepath, data_label):\n",
    "#     print('extracting for feature', data_label)\n",
    "    with open(data_sample_filepath, 'r') as csv_file:\n",
    "        # extract data records by row\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        sliding_windows = []\n",
    "        sliding_index = 0\n",
    "        window_step_forward = 1\n",
    "        window_length = 4\n",
    "        \n",
    "        # extract sliding windows from rows\n",
    "        sliding_window_csv = []\n",
    "        for row in reader:\n",
    "            sliding_window_csv.append(row)\n",
    "            if(len(sliding_window_csv) == window_length + 1):\n",
    "                del sliding_window_csv[0]\n",
    "            if(sliding_index % window_step_forward == 0 and len(sliding_window_csv) == window_length):\n",
    "                sliding_windows.append(list(sliding_window_csv))\n",
    "            sliding_index = sliding_index + 1\n",
    "        running_window_lines = []\n",
    "        \n",
    "        for feature_name, feature_func in feature_calculations.items():\n",
    "            for imu_data_column in imu_data_columns:\n",
    "                window_sequences = []\n",
    "                for sliding_window in sliding_windows:\n",
    "                    window_sequence = []\n",
    "                    for window in sliding_window:\n",
    "                        window_sequence.append(int(window[imu_data_column]))\n",
    "                    window_sequences.append(window_sequence)\n",
    "#                 print(imu_data_column, ' - ', window_sequences)\n",
    "                \n",
    "                window_index = 0\n",
    "                comma_index = 0;\n",
    "                window_count = len(window_sequences)\n",
    "                while len(running_window_lines) < window_count:\n",
    "                    running_window_lines.append('')\n",
    "                for window in window_sequences:\n",
    "                    running_window_lines[window_index % window_count] += (str(feature_func(window))) + ','\n",
    "#                     print(imu_data_column, ' _ ', feature_name, feature_func(window))\n",
    "                    window_index = window_index + 1\n",
    "#     print('PRINT FOR WINDOW ', window_count , running_window_lines)\n",
    "\n",
    "    with open(features_filepath, 'a') as features_file:\n",
    "        for feature_line in running_window_lines:\n",
    "            features_file.write(data_label + ',' + feature_line[:-1] + '\\n')\n",
    "            \n",
    "\n",
    "# Iterate through the raw IMU data directories and get their labels\n",
    "import glob\n",
    "import os\n",
    "labels = set()\n",
    "print('Extracting labels for samples in raw data directory:')\n",
    "for raw_data_dir in glob.glob('./data/training/raw/*', recursive=True):\n",
    "    labels.add(os.path.basename(raw_data_dir))\n",
    "print(labels)\n",
    "\n",
    "labels = set()\n",
    "print('Extracting labels for samples in raw data directory:')\n",
    "for raw_data_dir in glob.glob('./data/evaluation/raw/*', recursive=True):\n",
    "    labels.add(os.path.basename(raw_data_dir))\n",
    "print(labels)\n",
    "\n",
    "#os.remove('./data/features.csv')\n",
    "with open('./data/training-feature-data.csv', 'w') as file:\n",
    "    file.write('')\n",
    "\n",
    "with open('./data/evaluation-feature-data.csv', 'w') as file:\n",
    "    file.write('')\n",
    "\n",
    "# Don't include first csv row for training files\n",
    "#     running_line = 'label,'\n",
    "#     for feature_columns in feature_csv_columns:\n",
    "#         for imu_data_column in imu_data_columns:\n",
    "#             running_line += feature_columns + '_' + imu_data_column + ','\n",
    "#     running_line = running_line[:-1]\n",
    "#     running_line += '\\n'\n",
    "#     \n",
    "\n",
    "\n",
    "# Iterate through each raw IMU data sample and extract their features:\n",
    "for labelled_features in labels:\n",
    "    print('Extracting features for:', labelled_features)\n",
    "    for raw_data_dir in glob.glob('./data/training/raw/' + labelled_features + '/*.csv', recursive=False):\n",
    "        extract_features_from_imu_data_samples_for_label(raw_data_dir, './data/training-feature-data.csv', labelled_features)\n",
    "\n",
    "for labelled_features in labels:\n",
    "    print('Extracting features for:', labelled_features)\n",
    "    for raw_data_dir in glob.glob('./data/evaluation/raw/' + labelled_features + '/*.csv', recursive=False):\n",
    "        extract_features_from_imu_data_samples_for_label(raw_data_dir, './data/evaluation-feature-data.csv', labelled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implement a linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_service': None, '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000016F0F538710>, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_is_chief': True, '_save_checkpoints_steps': None, '_model_dir': './tmp/model', '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_tf_random_seed': None, '_master': '', '_keep_checkpoint_max': 5}\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 44.36142\n",
      "INFO:tensorflow:Loss for final step: 44.36142.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:35:42\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-1\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:35:43\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.6875, average_loss = 161.82494, global_step = 1, loss = 2589.199\n",
      "Results at epoch 2\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 2, loss = 7514.4995\n",
      "INFO:tensorflow:Loss for final step: 7514.4995.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:35:49\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-2\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:35:50\n",
      "INFO:tensorflow:Saving dict for global step 2: accuracy = 0.9375, average_loss = 32.263245, global_step = 2, loss = 516.2119\n",
      "Results at epoch 4\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-2\n",
      "INFO:tensorflow:Saving checkpoints for 3 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 3, loss = 1185.2816\n",
      "INFO:tensorflow:Loss for final step: 1185.2816.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:35:56\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-3\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:35:57\n",
      "INFO:tensorflow:Saving dict for global step 3: accuracy = 1.0, average_loss = 0.0, global_step = 3, loss = 0.0\n",
      "Results at epoch 6\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-3\n",
      "INFO:tensorflow:Saving checkpoints for 4 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 4, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:03\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-4\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:04\n",
      "INFO:tensorflow:Saving dict for global step 4: accuracy = 1.0, average_loss = 0.0, global_step = 4, loss = 0.0\n",
      "Results at epoch 8\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-4\n",
      "INFO:tensorflow:Saving checkpoints for 5 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 5, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:09\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-5\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:10\n",
      "INFO:tensorflow:Saving dict for global step 5: accuracy = 1.0, average_loss = 0.0, global_step = 5, loss = 0.0\n",
      "Results at epoch 10\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-5\n",
      "INFO:tensorflow:Saving checkpoints for 6 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 6, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:16\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-6\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:17\n",
      "INFO:tensorflow:Saving dict for global step 6: accuracy = 1.0, average_loss = 0.0, global_step = 6, loss = 0.0\n",
      "Results at epoch 12\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-6\n",
      "INFO:tensorflow:Saving checkpoints for 7 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 7, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:23\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-7\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:24\n",
      "INFO:tensorflow:Saving dict for global step 7: accuracy = 1.0, average_loss = 0.0, global_step = 7, loss = 0.0\n",
      "Results at epoch 14\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-7\n",
      "INFO:tensorflow:Saving checkpoints for 8 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 8, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:30\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-8\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:31\n",
      "INFO:tensorflow:Saving dict for global step 8: accuracy = 1.0, average_loss = 0.0, global_step = 8, loss = 0.0\n",
      "Results at epoch 16\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-8\n",
      "INFO:tensorflow:Saving checkpoints for 9 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 9, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:37\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-9\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:37\n",
      "INFO:tensorflow:Saving dict for global step 9: accuracy = 1.0, average_loss = 0.0, global_step = 9, loss = 0.0\n",
      "Results at epoch 18\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 10 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 10, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:43\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-10\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:44\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 1.0, average_loss = 0.0, global_step = 10, loss = 0.0\n",
      "Results at epoch 20\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-10\n",
      "INFO:tensorflow:Saving checkpoints for 11 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 11, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:50\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-11\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:51\n",
      "INFO:tensorflow:Saving dict for global step 11: accuracy = 1.0, average_loss = 0.0, global_step = 11, loss = 0.0\n",
      "Results at epoch 22\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-11\n",
      "INFO:tensorflow:Saving checkpoints for 12 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 12, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:36:57\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-12\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:36:58\n",
      "INFO:tensorflow:Saving dict for global step 12: accuracy = 1.0, average_loss = 0.0, global_step = 12, loss = 0.0\n",
      "Results at epoch 24\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-12\n",
      "INFO:tensorflow:Saving checkpoints for 13 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 13, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:37:03\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-13\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:37:04\n",
      "INFO:tensorflow:Saving dict for global step 13: accuracy = 1.0, average_loss = 0.0, global_step = 13, loss = 0.0\n",
      "Results at epoch 26\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-13\n",
      "INFO:tensorflow:Saving checkpoints for 14 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 14, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:37:10\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-14\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:37:11\n",
      "INFO:tensorflow:Saving dict for global step 14: accuracy = 1.0, average_loss = 0.0, global_step = 14, loss = 0.0\n",
      "Results at epoch 28\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-14\n",
      "INFO:tensorflow:Saving checkpoints for 15 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 15, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:37:17\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-15\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:37:18\n",
      "INFO:tensorflow:Saving dict for global step 15: accuracy = 1.0, average_loss = 0.0, global_step = 15, loss = 0.0\n",
      "Results at epoch 30\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-15\n",
      "INFO:tensorflow:Saving checkpoints for 16 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 16, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:37:24\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-16\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:37:25\n",
      "INFO:tensorflow:Saving dict for global step 16: accuracy = 1.0, average_loss = 0.0, global_step = 16, loss = 0.0\n",
      "Results at epoch 32\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-16\n",
      "INFO:tensorflow:Saving checkpoints for 17 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 17, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:37:31\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-17\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:37:32\n",
      "INFO:tensorflow:Saving dict for global step 17: accuracy = 1.0, average_loss = 0.0, global_step = 17, loss = 0.0\n",
      "Results at epoch 34\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-17\n",
      "INFO:tensorflow:Saving checkpoints for 18 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 18, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:37:37\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-18\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:37:38\n",
      "INFO:tensorflow:Saving dict for global step 18: accuracy = 1.0, average_loss = 0.0, global_step = 18, loss = 0.0\n",
      "Results at epoch 36\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-18\n",
      "INFO:tensorflow:Saving checkpoints for 19 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 19, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:37:44\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-19\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:37:45\n",
      "INFO:tensorflow:Saving dict for global step 19: accuracy = 1.0, average_loss = 0.0, global_step = 19, loss = 0.0\n",
      "Results at epoch 38\n",
      "------------------------------------------------------------\n",
      "PARSING: ./data/training-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-19\n",
      "INFO:tensorflow:Saving checkpoints for 20 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 20, loss = 0.0\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n",
      "PARSING: ./data/evaluation-feature-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-22-08:37:51\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-20\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-22-08:37:52\n",
      "INFO:tensorflow:Saving dict for global step 20: accuracy = 1.0, average_loss = 0.0, global_step = 20, loss = 0.0\n",
      "Results at epoch 40\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "model_dir='./tmp/model'\n",
    "train_data='./data/training-feature-data.csv'\n",
    "eval_data='./data/evaluation-feature-data.csv'\n",
    "\n",
    "# delete the model directory\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "# declare feature columns within csv\n",
    "median_gyro_roll = tf.feature_column.numeric_column(key='median_gyro_roll', dtype=tf.float64);\n",
    "median_gyro_pitch = tf.feature_column.numeric_column(key='median_gyro_pitch', dtype=tf.float64);\n",
    "median_gyro_yaw = tf.feature_column.numeric_column(key='median_gyro_yaw', dtype=tf.float64);\n",
    "\n",
    "median_acc_x = tf.feature_column.numeric_column(key='median_acc_x', dtype=tf.float64);\n",
    "median_acc_y = tf.feature_column.numeric_column(key='median_acc_y', dtype=tf.float64);\n",
    "median_acc_z = tf.feature_column.numeric_column(key='median_acc_z', dtype=tf.float64);\n",
    "\n",
    "mean_gyro_roll = tf.feature_column.numeric_column(key='mean_gyro_roll', dtype=tf.float64);\n",
    "mean_gyro_pitch = tf.feature_column.numeric_column(key='mean_gyro_pitch', dtype=tf.float64);\n",
    "mean_gyro_yaw = tf.feature_column.numeric_column(key='mean_gyro_yaw', dtype=tf.float64);\n",
    "\n",
    "# stack feature columns into a single array\n",
    "imu_window_feature_columns = [median_gyro_roll, median_gyro_pitch, median_gyro_yaw,\n",
    "        median_acc_x, median_acc_y, median_acc_z,\n",
    "        mean_gyro_roll, mean_gyro_pitch, mean_gyro_yaw]\n",
    "\n",
    "run_config=tf.estimator.RunConfig().replace(\n",
    "    session_config=tf.ConfigProto(device_count={'GPU': 0})\n",
    ")\n",
    "\n",
    "def input_fn(data_file):\n",
    "    assert tf.gfile.Exists(data_file),('%s not found')\n",
    "    records_default = [['0'],\n",
    "                       [0.0], [0.0], [0.0],\n",
    "                       [0.0], [0.0], [0.0],\n",
    "                       [0.0], [0.0], [0.0],\n",
    "                       [0.0], [0.0], [0.0]]\n",
    "    csv_columns = [\n",
    "                    'rotor',\n",
    "                    'mean_gyro_roll','mean_gyro_pitch','mean_gyro_yaw',\n",
    "                    'mean_acc_x','mean_acc_y','mean_acc_z',\n",
    "                    'median_gyro_roll','median_gyro_pitch','median_gyro_yaw',\n",
    "                    'median_acc_x','median_acc_y','median_acc_z'\n",
    "    ]\n",
    "    \n",
    "    def parse_csv(value):\n",
    "        print('PARSING:', data_file)\n",
    "        columns = tf.decode_csv(value, records_default)\n",
    "        features = dict(zip(csv_columns, columns))\n",
    "        labels = features.pop('rotor')\n",
    "        print('LABELS:', labels)\n",
    "        return features, labels\n",
    "    \n",
    "    dataset = tf.data.TextLineDataset(data_file)\n",
    "    dataset = dataset.shuffle(200)\n",
    "    dataset = dataset.map(parse_csv, 4)\n",
    "    dataset = dataset.batch(200)\n",
    "    return dataset\n",
    "\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir,\n",
    "    feature_columns=imu_window_feature_columns,\n",
    "    config=run_config,\n",
    "    n_classes=4,\n",
    "    label_vocabulary=['rotor1', 'rotor2', 'rotor3', 'rotor4']\n",
    ")\n",
    "# model = tf.estimator.DNNClassifier(\n",
    "#     model_dir=model_dir,\n",
    "#     feature_columns=imu_window_feature_columns,\n",
    "#     config=run_config,\n",
    "#     hidden_units=[100, 75, 50, 25],\n",
    "#     n_classes=4,\n",
    "#     label_vocabulary=['1', '2', '3', '4']\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# Train and evaluate the model every `FLAGS.epochs_per_eval` epochs.\n",
    "for n in range(40 // 2):\n",
    "    model.train(input_fn=lambda: input_fn(\n",
    "        train_data))\n",
    "\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(\n",
    "        eval_data))\n",
    "\n",
    "    # Display evaluation metrics\n",
    "    print('Results at epoch', (n + 1) * 2)\n",
    "    print('-' * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.train(input_fn=lambda: input_fn(\n",
    "#     train_data))\n",
    "\n",
    "# results = model.evaluate(input_fn=lambda:input_fn(\n",
    "#     train_data\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The directory is not empty.\n"
     ]
    }
   ],
   "source": [
    "% rmdir /s /q .\\tmp\\model-new\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
