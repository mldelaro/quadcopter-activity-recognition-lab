{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadcopter Activity Recognition \n",
    "\n",
    "Welcome to this training module that teaches you how to perform activity recognition with the help of a hosted Machine Learning instance. This notebook will guide you through the process of extracting information from your flight record!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "So let's start with what group name you are... this will help me pull your raw accelerometer data from the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import boto3.session\n",
    "import string\n",
    "\n",
    "access_key = 'AKIAJ32KO52IVG2C4ABA'\n",
    "secret_key = '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'\n",
    "\n",
    "session = boto3.session.Session(aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
    "s3 = session.resource(service_name='s3', endpoint_url=endpoint, verify=True)\n",
    "client = s3.meta.client\n",
    "\n",
    "GROUP_NAME = input('Group Name: ')\n",
    "print ('Pulling flight data from S3 for group [', GROUP_NAME ,'] ...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split flight data into windows of data samples for each label\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def extract_label_sets_from_file(data_filepath, destination_dir):\n",
    "    labelled_file = open(data_filepath, 'r')\n",
    "    \n",
    "    csv_columns = ['gyro_roll','gyro_pitch','gyro_yaw','acc_x','acc_y','acc_z']\n",
    "    \n",
    "    running_index = 0\n",
    "    running_label = ''\n",
    "    running_sample_index = {}\n",
    "    running_sample_filename = ''\n",
    "    labelled_row_reader = csv.DictReader(labelled_file)\n",
    "    for labelled_row in labelled_row_reader:\n",
    "        if(running_label != labelled_row['label']):\n",
    "            # Iterate sample file index for the current label\n",
    "            running_label = labelled_row['label']\n",
    "            if running_label in running_sample_index.keys():\n",
    "                running_sample_index[running_label] = running_sample_index[running_label] + 1;\n",
    "            else:\n",
    "                running_sample_index[running_label] = 0;\n",
    "            running_index = 0;\n",
    "            running_sample_filename = destination_dir + '/' + running_label + '/' + running_label + '-sample-' + str(running_sample_index[running_label]) + '.csv'\n",
    "            ensure_dir(running_sample_filename)\n",
    "            running_sample_file = open(running_sample_filename, 'w')\n",
    "            running_sample_file.write(','.join(csv_columns) + '\\n')\n",
    "            print('writing ' + labelled_row['gyro_roll']\n",
    "                                + ',' + labelled_row['gyro_pitch']\n",
    "                                + ',' + labelled_row['gyro_yaw']\n",
    "                                + ',' + labelled_row['acc_x']\n",
    "                                + ',' + labelled_row['acc_y']\n",
    "                                + ',' + labelled_row['acc_z'] + ' to ' + running_sample_filename)\n",
    "            running_sample_file.write(labelled_row['gyro_roll']\n",
    "                                + ',' + labelled_row['gyro_pitch']\n",
    "                                + ',' + labelled_row['gyro_yaw']\n",
    "                                + ',' + labelled_row['acc_x']\n",
    "                                + ',' + labelled_row['acc_y']\n",
    "                                + ',' + labelled_row['acc_z'] + '\\n')\n",
    "        else:\n",
    "            running_index = running_index + 1\n",
    "            print('writing ' + labelled_row['gyro_roll']\n",
    "                                + ',' + labelled_row['gyro_pitch']\n",
    "                                + ',' + labelled_row['gyro_yaw']\n",
    "                                + ',' + labelled_row['acc_x']\n",
    "                                + ',' + labelled_row['acc_y']\n",
    "                                + ',' + labelled_row['acc_z'] + ' to ' + running_sample_filename)\n",
    "            \n",
    "            running_sample_file.write(labelled_row['gyro_roll']\n",
    "                                + ',' + labelled_row['gyro_pitch']\n",
    "                                + ',' + labelled_row['gyro_yaw']\n",
    "                                + ',' + labelled_row['acc_x']\n",
    "                                + ',' + labelled_row['acc_y']\n",
    "                                + ',' + labelled_row['acc_z'] + '\\n')\n",
    "extract_label_sets_from_file('./data/training/raw/rotor-dummy-flight-record.csv', './data/training/raw/samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf2 = \"asdf\"\n",
    "\n",
    "print (asdf2 == \"asddf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below shows your flight control data that we pulled from S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data into a feature space\n",
    "Extract a features of a sliding window from a given sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting labels for samples in raw training data directory:\n",
      "{'rotor4', 'rotor3', 'rotor2', 'rotor1'}\n",
      "Extracting labels for samples in raw evaluation data directory:\n",
      "{'rotor4', 'rotor3', 'rotor2', 'rotor1'}\n",
      "Extracting features from ./data/training/raw/samples/rotor4\\rotor4-tap-45degree-sample3.csv\n",
      "Extracting for feature:  rotor4 from ./data/training/raw/samples/rotor4\\rotor4-tap-45degree-sample3.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor4\\rotor4-tap-45degree-sample4.csv\n",
      "Extracting for feature:  rotor4 from ./data/training/raw/samples/rotor4\\rotor4-tap-45degree-sample4.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor4\\rotor4-tap-45degree-sample5.csv\n",
      "Extracting for feature:  rotor4 from ./data/training/raw/samples/rotor4\\rotor4-tap-45degree-sample5.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor4\\rotor4-tap-45degree-sample6.csv\n",
      "Extracting for feature:  rotor4 from ./data/training/raw/samples/rotor4\\rotor4-tap-45degree-sample6.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor3\\rotor3-tap-45degree-sample3.csv\n",
      "Extracting for feature:  rotor3 from ./data/training/raw/samples/rotor3\\rotor3-tap-45degree-sample3.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor3\\rotor3-tap-45degree-sample4.csv\n",
      "Extracting for feature:  rotor3 from ./data/training/raw/samples/rotor3\\rotor3-tap-45degree-sample4.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor3\\rotor3-tap-45degree-sample5.csv\n",
      "Extracting for feature:  rotor3 from ./data/training/raw/samples/rotor3\\rotor3-tap-45degree-sample5.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor3\\rotor3-tap-45degree-sample6.csv\n",
      "Extracting for feature:  rotor3 from ./data/training/raw/samples/rotor3\\rotor3-tap-45degree-sample6.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor2\\rotor2-tap-45degree-sample3.csv\n",
      "Extracting for feature:  rotor2 from ./data/training/raw/samples/rotor2\\rotor2-tap-45degree-sample3.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor2\\rotor2-tap-45degree-sample4.csv\n",
      "Extracting for feature:  rotor2 from ./data/training/raw/samples/rotor2\\rotor2-tap-45degree-sample4.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor2\\rotor2-tap-45degree-sample5.csv\n",
      "Extracting for feature:  rotor2 from ./data/training/raw/samples/rotor2\\rotor2-tap-45degree-sample5.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor2\\rotor2-tap-45degree-sample6.csv\n",
      "Extracting for feature:  rotor2 from ./data/training/raw/samples/rotor2\\rotor2-tap-45degree-sample6.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor1\\rotor1-tap-45degree-sample3.csv\n",
      "Extracting for feature:  rotor1 from ./data/training/raw/samples/rotor1\\rotor1-tap-45degree-sample3.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor1\\rotor1-tap-45degree-sample4.csv\n",
      "Extracting for feature:  rotor1 from ./data/training/raw/samples/rotor1\\rotor1-tap-45degree-sample4.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor1\\rotor1-tap-45degree-sample5.csv\n",
      "Extracting for feature:  rotor1 from ./data/training/raw/samples/rotor1\\rotor1-tap-45degree-sample5.csv\n",
      "Extracting features from ./data/training/raw/samples/rotor1\\rotor1-tap-45degree-sample6.csv\n",
      "Extracting for feature:  rotor1 from ./data/training/raw/samples/rotor1\\rotor1-tap-45degree-sample6.csv\n",
      "Extracting features from ./data/evaluation/raw/samples/rotor4\\rotor4-sample-0.csv\n",
      "Extracting for feature:  rotor4 from ./data/evaluation/raw/samples/rotor4\\rotor4-sample-0.csv\n",
      "Extracting features from ./data/evaluation/raw/samples/rotor3\\rotor3-sample-0.csv\n",
      "Extracting for feature:  rotor3 from ./data/evaluation/raw/samples/rotor3\\rotor3-sample-0.csv\n",
      "Extracting features from ./data/evaluation/raw/samples/rotor2\\rotor2-sample-0.csv\n",
      "Extracting for feature:  rotor2 from ./data/evaluation/raw/samples/rotor2\\rotor2-sample-0.csv\n",
      "Extracting features from ./data/evaluation/raw/samples/rotor1\\rotor1-sample-0.csv\n",
      "Extracting for feature:  rotor1 from ./data/evaluation/raw/samples/rotor1\\rotor1-sample-0.csv\n",
      "Extracting features from ./data/evaluation/raw/samples/rotor1\\rotor1-sample-1.csv\n",
      "Extracting for feature:  rotor1 from ./data/evaluation/raw/samples/rotor1\\rotor1-sample-1.csv\n",
      "File too short [./data/evaluation/raw/samples/rotor1\\rotor1-sample-1.csv]\n"
     ]
    }
   ],
   "source": [
    "#TODO: Change rotor label to the appropriate flight controls\n",
    "import csv\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "FEATURE_DATA_FILEPATH = './data/'\n",
    "\n",
    "feature_csv_columns = ['average', 'median']\n",
    "imu_data_columns = ['gyro_roll', 'gyro_pitch', 'gyro_yaw', 'acc_x', 'acc_y', 'acc_z']\n",
    "\n",
    "def feature_average(data_sample):\n",
    "    fSum = 0;\n",
    "    nIndex = 0;\n",
    "    for data in data_sample:\n",
    "        fSum = fSum + data\n",
    "        nIndex = nIndex + 1\n",
    "    return float(fSum / nIndex)\n",
    "\n",
    "def feature_variance(data_sample):\n",
    "    return np.var(data_sample)\n",
    "\n",
    "def feature_median(data_sample):\n",
    "    return np.median(data_sample, axis=0)\n",
    "\n",
    "feature_calculations = {\n",
    "    'average' : feature_average,\n",
    "    'median' : feature_median\n",
    "}\n",
    "\n",
    "# Read a *.csv file and extract the sliding window\n",
    "import collections\n",
    "def extract_features_from_imu_data_samples_for_label(data_sample_filepath, features_filepath, data_label):\n",
    "    print('Extracting for feature: ', data_label, 'from', data_sample_filepath)\n",
    "    with open(data_sample_filepath, 'r') as csv_file:\n",
    "        # extract data records by row\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        sliding_windows = []\n",
    "        sliding_index = 0\n",
    "        window_step_forward = 1\n",
    "        window_length = 4\n",
    "        \n",
    "        if(len(list(reader)) < window_length):\n",
    "            print('File too short [' + data_sample_filepath + ']')\n",
    "            return\n",
    "        \n",
    "        # extract sliding windows from rows\n",
    "        sliding_window_csv = []\n",
    "        for row in reader:\n",
    "            print('asdf ', row)\n",
    "            sliding_window_csv.append(row)\n",
    "            if(len(sliding_window_csv) == window_length + 1):\n",
    "                del sliding_window_csv[0]\n",
    "            if(sliding_index % window_step_forward == 0 and len(sliding_window_csv) == window_length):\n",
    "                sliding_windows.append(list(sliding_window_csv))\n",
    "            sliding_index = sliding_index + 1\n",
    "        running_window_lines = []\n",
    "        \n",
    "        for feature_name, feature_func in feature_calculations.items():\n",
    "            for imu_data_column in imu_data_columns:\n",
    "                window_sequences = []\n",
    "                for sliding_window in sliding_windows:\n",
    "                    window_sequence = []\n",
    "                    for window in sliding_window:\n",
    "                        window_sequence.append(int(window[imu_data_column]))\n",
    "                    window_sequences.append(window_sequence)\n",
    "#                 print(imu_data_column, ' - ', window_sequences)\n",
    "                \n",
    "                window_index = 0\n",
    "                comma_index = 0;\n",
    "                window_count = len(window_sequences)\n",
    "                while len(running_window_lines) < window_count:\n",
    "                    running_window_lines.append('')\n",
    "                for window in window_sequences:\n",
    "                    running_window_lines[window_index % window_count] += (str(feature_func(window))) + ','\n",
    "#                     print(imu_data_column, ' _ ', feature_name, feature_func(window))\n",
    "                    window_index = window_index + 1\n",
    "#     print('PRINT FOR WINDOW ', window_count , running_window_lines)\n",
    "\n",
    "    with open(features_filepath, 'a') as features_file:\n",
    "        for feature_line in running_window_lines:\n",
    "            features_file.write(data_label + ',' + feature_line[:-1] + '\\n')\n",
    "            \n",
    "\n",
    "# Iterate through the raw IMU data directories and get their labels\n",
    "import glob\n",
    "import os\n",
    "labels = set()\n",
    "print('Extracting labels for samples in raw training data directory:')\n",
    "for raw_data_dir in glob.glob('./data/training/raw/samples/*', recursive=True):\n",
    "    labels.add(os.path.basename(raw_data_dir))\n",
    "print(labels)\n",
    "\n",
    "labels = set()\n",
    "print('Extracting labels for samples in raw evaluation data directory:')\n",
    "for raw_data_dir in glob.glob('./data/evaluation/raw/samples/*', recursive=True):\n",
    "    labels.add(os.path.basename(raw_data_dir))\n",
    "print(labels)\n",
    "\n",
    "#os.remove('./data/features.csv')\n",
    "with open('./data/training-feature-data.csv', 'w') as file:\n",
    "    file.write('')\n",
    "\n",
    "with open('./data/evaluation-feature-data.csv', 'w') as file:\n",
    "    file.write('')\n",
    "\n",
    "# Don't include first csv row for training files\n",
    "#     running_line = 'label,'\n",
    "#     for feature_columns in feature_csv_columns:\n",
    "#         for imu_data_column in imu_data_columns:\n",
    "#             running_line += feature_columns + '_' + imu_data_column + ','\n",
    "#     running_line = running_line[:-1]\n",
    "#     running_line += '\\n'\n",
    "#     \n",
    "\n",
    "\n",
    "# Iterate through each raw IMU data sample and extract their features:\n",
    "for labelled_features in labels:\n",
    "    for raw_data_dir in glob.glob('./data/training/raw/samples/' + labelled_features + '/*.csv', recursive=False):\n",
    "        print(\"Extracting features from \" + raw_data_dir)\n",
    "        extract_features_from_imu_data_samples_for_label(raw_data_dir, './data/training-feature-data.csv', labelled_features)\n",
    "\n",
    "for labelled_features in labels:\n",
    "    for raw_data_dir in glob.glob('./data/evaluation/raw/samples/' + labelled_features + '/*.csv', recursive=False):\n",
    "        print(\"Extracting features from \" + raw_data_dir)\n",
    "        extract_features_from_imu_data_samples_for_label(raw_data_dir, './data/evaluation-feature-data.csv', labelled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implement a linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "model_dir='./tmp/model'\n",
    "train_data='./data/training-feature-data.csv'\n",
    "eval_data='./data/evaluation-feature-data.csv'\n",
    "\n",
    "# delete the model directory\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "# declare feature columns within csv\n",
    "median_gyro_roll = tf.feature_column.numeric_column(key='median_gyro_roll', dtype=tf.float64);\n",
    "median_gyro_pitch = tf.feature_column.numeric_column(key='median_gyro_pitch', dtype=tf.float64);\n",
    "median_gyro_yaw = tf.feature_column.numeric_column(key='median_gyro_yaw', dtype=tf.float64);\n",
    "\n",
    "median_acc_x = tf.feature_column.numeric_column(key='median_acc_x', dtype=tf.float64);\n",
    "median_acc_y = tf.feature_column.numeric_column(key='median_acc_y', dtype=tf.float64);\n",
    "median_acc_z = tf.feature_column.numeric_column(key='median_acc_z', dtype=tf.float64);\n",
    "\n",
    "mean_gyro_roll = tf.feature_column.numeric_column(key='mean_gyro_roll', dtype=tf.float64);\n",
    "mean_gyro_pitch = tf.feature_column.numeric_column(key='mean_gyro_pitch', dtype=tf.float64);\n",
    "mean_gyro_yaw = tf.feature_column.numeric_column(key='mean_gyro_yaw', dtype=tf.float64);\n",
    "\n",
    "# stack feature columns into a single array\n",
    "imu_window_feature_columns = [median_gyro_roll, median_gyro_pitch, median_gyro_yaw,\n",
    "        median_acc_x, median_acc_y, median_acc_z,\n",
    "        mean_gyro_roll, mean_gyro_pitch, mean_gyro_yaw]\n",
    "\n",
    "run_config=tf.estimator.RunConfig().replace(\n",
    "    session_config=tf.ConfigProto(device_count={'GPU': 0})\n",
    ")\n",
    "\n",
    "def input_fn(data_file):\n",
    "    assert tf.gfile.Exists(data_file),('%s not found')\n",
    "    records_default = [['0'],\n",
    "                       [0.0], [0.0], [0.0],\n",
    "                       [0.0], [0.0], [0.0],\n",
    "                       [0.0], [0.0], [0.0],\n",
    "                       [0.0], [0.0], [0.0]]\n",
    "    csv_columns = [\n",
    "                    'rotor',\n",
    "                    'mean_gyro_roll','mean_gyro_pitch','mean_gyro_yaw',\n",
    "                    'mean_acc_x','mean_acc_y','mean_acc_z',\n",
    "                    'median_gyro_roll','median_gyro_pitch','median_gyro_yaw',\n",
    "                    'median_acc_x','median_acc_y','median_acc_z'\n",
    "    ]\n",
    "    \n",
    "    def parse_csv(value):\n",
    "        print('PARSING:', data_file)\n",
    "        columns = tf.decode_csv(value, records_default)\n",
    "        features = dict(zip(csv_columns, columns))\n",
    "        labels = features.pop('rotor')\n",
    "        print('LABELS:', labels)\n",
    "        return features, labels\n",
    "    \n",
    "    dataset = tf.data.TextLineDataset(data_file)\n",
    "    dataset = dataset.shuffle(200)\n",
    "    dataset = dataset.map(parse_csv, 4)\n",
    "    dataset = dataset.batch(200)\n",
    "    return dataset\n",
    "\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir,\n",
    "    feature_columns=imu_window_feature_columns,\n",
    "    config=run_config,\n",
    "    n_classes=4,\n",
    "    label_vocabulary=['rotor1', 'rotor2', 'rotor3', 'rotor4']\n",
    ")\n",
    "# model = tf.estimator.DNNClassifier(\n",
    "#     model_dir=model_dir,\n",
    "#     feature_columns=imu_window_feature_columns,\n",
    "#     config=run_config,\n",
    "#     hidden_units=[100, 75, 50, 25],\n",
    "#     n_classes=4,\n",
    "#     label_vocabulary=['1', '2', '3', '4']\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "#  <=== Train and evaluate the model every `FLAGS.epochs_per_eval` epochs.  ===>\n",
    "# for n in range(40 // 2):\n",
    "#     model.train(input_fn=lambda: input_fn(\n",
    "#         train_data))\n",
    "\n",
    "#     results = model.evaluate(input_fn=lambda: input_fn(\n",
    "#         eval_data))\n",
    "\n",
    "#     # Display evaluation metricshttps://docs.aws.amazon.com/sagemaker/latest/dg/tf-training-inference-code-template.html\n",
    "#     print('Results at epoch', (n + 1) * 2)\n",
    "#     print('-' * 60)\n",
    "\n",
    "print('[DONE]')\n",
    "\n",
    "model.train(input_fn=lambda: input_fn(\n",
    "    train_data))\n",
    "\n",
    "results = model.evaluate(input_fn=lambda:input_fn(\n",
    "    train_data\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
