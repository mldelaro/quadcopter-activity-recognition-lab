{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello linear model\n",
    "This tutorial is part of the Tensorflow getting started documentation at: https://www.tensorflow.org/tutorials/wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert raw IMU raw data into features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw .csv data\n",
    "\n",
    "\n",
    "#Extract sliding windows from raw imu data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000024AD0004B70>, '_save_checkpoints_secs': 600, '_is_chief': True, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_task_type': 'worker', '_task_id': 0, '_keep_checkpoint_max': 5, '_model_dir': './tmp/model', '_service': None, '_master': '', '_num_worker_replicas': 1, '_tf_random_seed': None, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000}\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 8203.593\n",
      "INFO:tensorflow:Loss for final step: 8203.593.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:20:09\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-1\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:20:10\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.25, average_loss = 1280.2885, global_step = 1, loss = 20484.615\n",
      "Results at epoch 2\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 2, loss = 20484.615\n",
      "INFO:tensorflow:Loss for final step: 20484.615.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:20:16\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-2\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:20:17\n",
      "INFO:tensorflow:Saving dict for global step 2: accuracy = 0.25, average_loss = 3160.0488, global_step = 2, loss = 50560.78\n",
      "Results at epoch 4\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-2\n",
      "INFO:tensorflow:Saving checkpoints for 3 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 3, loss = 50560.78\n",
      "INFO:tensorflow:Loss for final step: 50560.78.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:20:23\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-3\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:20:24\n",
      "INFO:tensorflow:Saving dict for global step 3: accuracy = 0.25, average_loss = 434.56168, global_step = 3, loss = 6952.987\n",
      "Results at epoch 6\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-3\n",
      "INFO:tensorflow:Saving checkpoints for 4 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 4, loss = 6952.9873\n",
      "INFO:tensorflow:Loss for final step: 6952.9873.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:20:30\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-4\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:20:30\n",
      "INFO:tensorflow:Saving dict for global step 4: accuracy = 0.5, average_loss = 70.99979, global_step = 4, loss = 1135.9966\n",
      "Results at epoch 8\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-4\n",
      "INFO:tensorflow:Saving checkpoints for 5 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 5, loss = 1135.9966\n",
      "INFO:tensorflow:Loss for final step: 1135.9966.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:20:36\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-5\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:20:37\n",
      "INFO:tensorflow:Saving dict for global step 5: accuracy = 0.5625, average_loss = 73.13263, global_step = 5, loss = 1170.1221\n",
      "Results at epoch 10\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-5\n",
      "INFO:tensorflow:Saving checkpoints for 6 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 6, loss = 1170.1221\n",
      "INFO:tensorflow:Loss for final step: 1170.1221.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:20:43\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-6\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:20:44\n",
      "INFO:tensorflow:Saving dict for global step 6: accuracy = 0.625, average_loss = 28.100796, global_step = 6, loss = 449.61273\n",
      "Results at epoch 12\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-6\n",
      "INFO:tensorflow:Saving checkpoints for 7 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 7, loss = 449.61273\n",
      "INFO:tensorflow:Loss for final step: 449.61273.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:20:50\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-7\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:20:51\n",
      "INFO:tensorflow:Saving dict for global step 7: accuracy = 0.5, average_loss = 37.56776, global_step = 7, loss = 601.08417\n",
      "Results at epoch 14\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-7\n",
      "INFO:tensorflow:Saving checkpoints for 8 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 8, loss = 601.0842\n",
      "INFO:tensorflow:Loss for final step: 601.0842.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:20:57\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-8\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:20:58\n",
      "INFO:tensorflow:Saving dict for global step 8: accuracy = 0.6875, average_loss = 18.792633, global_step = 8, loss = 300.68213\n",
      "Results at epoch 16\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-8\n",
      "INFO:tensorflow:Saving checkpoints for 9 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 9, loss = 300.68213\n",
      "INFO:tensorflow:Loss for final step: 300.68213.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:21:05\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-9\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:21:05\n",
      "INFO:tensorflow:Saving dict for global step 9: accuracy = 0.625, average_loss = 10.853344, global_step = 9, loss = 173.6535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at epoch 18\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-9\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 10, loss = 173.6535\n",
      "INFO:tensorflow:Loss for final step: 173.6535.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:21:11\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-10\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:21:12\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.75, average_loss = 9.223247, global_step = 10, loss = 147.57195\n",
      "Results at epoch 20\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-10\n",
      "INFO:tensorflow:Saving checkpoints for 11 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 11, loss = 147.57195\n",
      "INFO:tensorflow:Loss for final step: 147.57195.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:21:18\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-11\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:21:19\n",
      "INFO:tensorflow:Saving dict for global step 11: accuracy = 0.6875, average_loss = 7.2425823, global_step = 11, loss = 115.88132\n",
      "Results at epoch 22\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-11\n",
      "INFO:tensorflow:Saving checkpoints for 12 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 12, loss = 115.88131\n",
      "INFO:tensorflow:Loss for final step: 115.88131.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:21:25\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-12\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:21:26\n",
      "INFO:tensorflow:Saving dict for global step 12: accuracy = 0.6875, average_loss = 5.3596344, global_step = 12, loss = 85.75415\n",
      "Results at epoch 24\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-12\n",
      "INFO:tensorflow:Saving checkpoints for 13 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 13, loss = 85.75415\n",
      "INFO:tensorflow:Loss for final step: 85.75415.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:21:33\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-13\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:21:34\n",
      "INFO:tensorflow:Saving dict for global step 13: accuracy = 0.75, average_loss = 7.857335, global_step = 13, loss = 125.71736\n",
      "Results at epoch 26\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-13\n",
      "INFO:tensorflow:Saving checkpoints for 14 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 14, loss = 125.71736\n",
      "INFO:tensorflow:Loss for final step: 125.71736.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:21:40\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-14\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:21:40\n",
      "INFO:tensorflow:Saving dict for global step 14: accuracy = 0.75, average_loss = 2.4570894, global_step = 14, loss = 39.31343\n",
      "Results at epoch 28\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-14\n",
      "INFO:tensorflow:Saving checkpoints for 15 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 15, loss = 39.31343\n",
      "INFO:tensorflow:Loss for final step: 39.31343.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:21:46\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-15\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:21:47\n",
      "INFO:tensorflow:Saving dict for global step 15: accuracy = 0.8125, average_loss = 1.0127374, global_step = 15, loss = 16.203798\n",
      "Results at epoch 30\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-15\n",
      "INFO:tensorflow:Saving checkpoints for 16 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 16, loss = 16.203798\n",
      "INFO:tensorflow:Loss for final step: 16.203798.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:21:53\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-16\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:21:54\n",
      "INFO:tensorflow:Saving dict for global step 16: accuracy = 0.875, average_loss = 1.0346535, global_step = 16, loss = 16.554457\n",
      "Results at epoch 32\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-16\n",
      "INFO:tensorflow:Saving checkpoints for 17 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 17, loss = 16.554457\n",
      "INFO:tensorflow:Loss for final step: 16.554457.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:22:00\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-17\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:22:01\n",
      "INFO:tensorflow:Saving dict for global step 17: accuracy = 0.9375, average_loss = 1.816455, global_step = 17, loss = 29.06328\n",
      "Results at epoch 34\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-17\n",
      "INFO:tensorflow:Saving checkpoints for 18 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 18, loss = 29.063282\n",
      "INFO:tensorflow:Loss for final step: 29.063282.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:22:07\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-18\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:22:08\n",
      "INFO:tensorflow:Saving dict for global step 18: accuracy = 0.9375, average_loss = 0.1662489, global_step = 18, loss = 2.6599824\n",
      "Results at epoch 36\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-18\n",
      "INFO:tensorflow:Saving checkpoints for 19 into ./tmp/model\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 19, loss = 2.6599824\n",
      "INFO:tensorflow:Loss for final step: 2.6599824.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:22:14\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-19\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:22:15\n",
      "INFO:tensorflow:Saving dict for global step 19: accuracy = 0.875, average_loss = 0.26922363, global_step = 19, loss = 4.307578\n",
      "Results at epoch 38\n",
      "------------------------------------------------------------\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-19\n",
      "INFO:tensorflow:Saving checkpoints for 20 into ./tmp/model\\model.ckpt.\n",
      "INFO:tensorflow:step = 20, loss = 4.307578\n",
      "INFO:tensorflow:Loss for final step: 4.307578.\n",
      "PARSING: ./sample-data/rotor-tap-sample-data.csv\n",
      "LABELS: Tensor(\"DecodeCSV:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-17-23:22:21\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model\\model.ckpt-20\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-17-23:22:22\n",
      "INFO:tensorflow:Saving dict for global step 20: accuracy = 0.9375, average_loss = 1.3087993, global_step = 20, loss = 20.940788\n",
      "Results at epoch 40\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "model_dir='./tmp/model'\n",
    "train_data='./sample-data/rotor-tap-sample-data.csv'\n",
    "\n",
    "# delete the model directory\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "# declare feature columns within csv\n",
    "median_gyro_roll = tf.feature_column.numeric_column(key='median-gyro-roll', dtype=tf.float64);\n",
    "median_gyro_pitch = tf.feature_column.numeric_column(key='median-gyro-pitch', dtype=tf.float64);\n",
    "median_gyro_yaw = tf.feature_column.numeric_column(key='median-gyro-yaw', dtype=tf.float64);\n",
    "\n",
    "median_acc_x = tf.feature_column.numeric_column(key='median-acc-x', dtype=tf.float64);\n",
    "median_acc_y = tf.feature_column.numeric_column(key='median-acc-y', dtype=tf.float64);\n",
    "median_acc_z = tf.feature_column.numeric_column(key='median-acc-z', dtype=tf.float64);\n",
    "\n",
    "mean_gyro_roll = tf.feature_column.numeric_column(key='mean-gyro-roll', dtype=tf.float64);\n",
    "mean_gyro_pitch = tf.feature_column.numeric_column(key='mean-gyro-pitch', dtype=tf.float64);\n",
    "mean_gyro_yaw = tf.feature_column.numeric_column(key='mean-gyro-yaw', dtype=tf.float64);\n",
    "\n",
    "# stack feature columns into a single array\n",
    "imu_window_feature_columns = [median_gyro_roll, median_gyro_pitch, median_gyro_yaw,\n",
    "        median_acc_x, median_acc_y, median_acc_z,\n",
    "        mean_gyro_roll, mean_gyro_pitch, mean_gyro_yaw]\n",
    "\n",
    "run_config=tf.estimator.RunConfig().replace(\n",
    "    session_config=tf.ConfigProto(device_count={'GPU': 0})\n",
    ")\n",
    "\n",
    "def input_fn(data_file):\n",
    "    assert tf.gfile.Exists(data_file),('%s not found')\n",
    "    records_default = [['0'], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],\n",
    "                       [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
    "    csv_columns = [\n",
    "                    'rotor',\n",
    "                    'median-gyro-roll','median-gyro-pitch','median-gyro-yaw',\n",
    "                    'median-acc-x','median-acc-y','median-acc-z',\n",
    "                    'mean-gyro-roll','mean-gyro-pitch','mean-gyro-yaw',\n",
    "                    'mean-acc-x','mean-acc-y','mean-acc-z',\n",
    "                    'skew-gyro-roll','skew-gyro-pitch','skew-gyro-yaw',\n",
    "                    'skew-acc-x','skew-acc-y','skew-acc-z'\n",
    "                  ]\n",
    "    \n",
    "    def parse_csv(value):\n",
    "        print('PARSING:', data_file)\n",
    "        columns = tf.decode_csv(value, records_default)\n",
    "        features = dict(zip(csv_columns, columns))\n",
    "        labels = features.pop('rotor')\n",
    "        print('LABELS:', labels)\n",
    "        return features, labels\n",
    "    \n",
    "    dataset = tf.data.TextLineDataset(data_file)\n",
    "    dataset = dataset.shuffle(200)\n",
    "    dataset = dataset.map(parse_csv, 4)\n",
    "    dataset = dataset.batch(200)\n",
    "    return dataset\n",
    "\n",
    "# model = tf.estimator.LinearClassifier(\n",
    "#     model_dir=model_dir,\n",
    "#     feature_columns=columns,\n",
    "#     config=run_config,\n",
    "#     n_classes=4,\n",
    "#     label_vocabulary=['1', '2', '3', '4']\n",
    "# )\n",
    "model = tf.estimator.DNNClassifier(\n",
    "    model_dir=model_dir,\n",
    "    feature_columns=columns,\n",
    "    config=run_config,\n",
    "    hidden_units=[100, 75, 50, 25],\n",
    "    n_classes=4,\n",
    "    label_vocabulary=['1', '2', '3', '4']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Train and evaluate the model every `FLAGS.epochs_per_eval` epochs.\n",
    "for n in range(40 // 2):\n",
    "    model.train(input_fn=lambda: input_fn(\n",
    "        train_data))\n",
    "\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(\n",
    "        train_data))\n",
    "\n",
    "    # Display evaluation metrics\n",
    "    print('Results at epoch', (n + 1) * 2)\n",
    "    print('-' * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.train(input_fn=lambda: input_fn(\n",
    "#     train_data))\n",
    "\n",
    "# results = model.evaluate(input_fn=lambda:input_fn(\n",
    "#     train_data\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Moving to the wide_deep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'age_buckets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-132af60e54ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    122\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-132af60e54ef>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;31m# Clean up the model directory if present\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;31m# Train and evaluate the model every `FLAGS.epochs_per_eval` epochs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-132af60e54ef>\u001b[0m in \u001b[0;36mbuild_estimator\u001b[1;34m(model_dir, model_type)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;34m\"\"\"Build an estimator appropriate for the given model type.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mwide_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mhidden_units\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-132af60e54ef>\u001b[0m in \u001b[0;36mbuild_model_columns\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m             ['education', 'occupation'], hash_bucket_size=1000),\n\u001b[0;32m     66\u001b[0m         tf.feature_column.crossed_column(\n\u001b[1;32m---> 67\u001b[1;33m             [age_buckets, 'education', 'occupation'], hash_bucket_size=1000),\n\u001b[0m\u001b[0;32m     68\u001b[0m     ]\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'age_buckets' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Example code for TensorFlow Wide & Deep Tutorial using tf.estimator API.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "_CSV_COLUMNS = [\n",
    "    'accelerometer_x', 'accelerometer_y', 'accelerometer_z',\n",
    "    'gyrometer_x', 'gyrometer_y', 'gyrometer_z'\n",
    "]\n",
    "\n",
    "_CSV_COLUMN_DEFAULTS = [[0], [0], [0],\n",
    "                        [0], [0], [0]]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    '--model_dir', type=str, default='./tmp/census-model',\n",
    "    help='Base directory for the model.')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--model_type', type=str, default='wide',\n",
    "    help=\"Valid model types: {'wide', 'deep', 'wide_deep'}.\")\n",
    "\n",
    "parser.add_argument(\n",
    "    '--train_epochs', type=int, default=40, help='Number of training epochs.')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--epochs_per_eval', type=int, default=2,\n",
    "    help='The number of training epochs to run between evaluations.')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--batch_size', type=int, default=40, help='Number of examples per batch.')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--train_data', type=str, default='./sample-data/adult.data',\n",
    "    help='Path to the training data.')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--test_data', type=str, default='./sample-data/adult.test',\n",
    "    help='Path to the test data.')\n",
    "\n",
    "_NUM_EXAMPLES = {\n",
    "    'train': 32561,\n",
    "    'validation': 16281,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def build_model_columns():\n",
    "    \"\"\"Builds a set of wide and deep feature columns.\"\"\"\n",
    "    # Continuous columns\n",
    "    gyroRoll = tf.feature_column.numeric_column('gyro_roll')\n",
    "    gyroPitch = tf.feature_column.numeric_column('gyro_pitch')\n",
    "    gyroYaw = tf.feature_column.numeric_column('gyro_yaw')\n",
    "    accelerometerX = tf.feature_column.numeric_column('accelerometer_x')\n",
    "    accelerometerY = tf.feature_column.numeric_column('accelerometer_y')\n",
    "    accelerometerZ = tf.feature_column.numeric_column('accelerometer_z')\n",
    "    \n",
    "    base_columns = [\n",
    "        gyroRoll, gyroPitch, gyroYaw, accelerometerX, accelerometerY, accelerometerZ\n",
    "    ]\n",
    "    crossed_columns = []\n",
    "    \n",
    "#     crossed_columns = [\n",
    "#         tf.feature_column.crossed_column(\n",
    "#             ['education', 'occupation'], hash_bucket_size=1000),\n",
    "#         tf.feature_column.crossed_column(\n",
    "#             [age_buckets, 'education', 'occupation'], hash_bucket_size=1000),\n",
    "#     ]\n",
    "    \n",
    "    wide_columns = base_columns + crossed_columns\n",
    "    deep_columns= []\n",
    "#     deep_columns = [\n",
    "#         age,\n",
    "#         education_num,\n",
    "#         capital_gain,\n",
    "#         capital_loss,\n",
    "#         hours_per_week,\n",
    "#         tf.feature_column.indicator_column(workclass),\n",
    "#         tf.feature_column.indicator_column(education),\n",
    "#         tf.feature_column.indicator_column(marital_status),\n",
    "#         tf.feature_column.indicator_column(relationship),\n",
    "#         # To show an example of embedding\n",
    "#         tf.feature_column.embedding_column(occupation, dimension=8),\n",
    "#     ]\n",
    "    return wide_columns, deep_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_estimator(model_dir, model_type):\n",
    "    \"\"\"Build an estimator appropriate for the given model type.\"\"\"\n",
    "    wide_columns, deep_columns = build_model_columns()\n",
    "    #hidden_units = [100, 75, 50, 25]\n",
    "    \n",
    "    # Create a tf.estimator.RunConfig to ensure the model is run on CPU, which\n",
    "    # trains faster than GPU for this model.\n",
    "    run_config = tf.estimator.RunConfig().replace(\n",
    "        session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "    if model_type == 'wide':\n",
    "        return tf.estimator.LinearClassifier(\n",
    "            model_dir=model_dir,\n",
    "            feature_columns=wide_columns,\n",
    "            config=run_config)\n",
    "#     elif model_type == 'deep':\n",
    "#         return tf.estimator.DNNClassifier(\n",
    "#             model_dir=model_dir,\n",
    "#             feature_columns=deep_columns,\n",
    "#             hidden_units=hidden_units,\n",
    "#             config=run_config)\n",
    "#     else:\n",
    "#         return tf.estimator.DNNLinearCombinedClassifier(\n",
    "#             model_dir=model_dir,\n",
    "#             linear_feature_columns=wide_columns,\n",
    "#             dnn_feature_columns=deep_columns,\n",
    "#             dnn_hidden_units=hidden_units,\n",
    "#             config=run_config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_raw_gyro_accelerometer_data(data_file):\n",
    "    sliding_sample = \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "    \"\"\"Generate an input function for the Estimator.\"\"\"\n",
    "    assert tf.gfile.Exists(data_file), (\n",
    "        '%s not found. Please make sure you have either run data_download.py or '\n",
    "        'set both arguments --train_data and --test_data.' % data_file)\n",
    "\n",
    "    def parse_csv(value):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
    "        #features = dict(zip(_CSV_COLUMNS, columns))\n",
    "        #labels = features.pop('income_bracket')\n",
    "        #return features, tf.equal(labels, '>50K')\n",
    "        return features, \"unlabeled\"\n",
    "\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = tf.data.TextLineDataset(data_file)\n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
    "    \n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "    # Clean up the model directory if present\n",
    "    shutil.rmtree(FLAGS.model_dir, ignore_errors=True)\n",
    "    model = build_estimator(FLAGS.model_dir, FLAGS.model_type)\n",
    "\n",
    "    # Train and evaluate the model every `FLAGS.epochs_per_eval` epochs.\n",
    "    for n in range(FLAGS.train_epochs // FLAGS.epochs_per_eval):\n",
    "        model.train(input_fn=lambda: input_fn(\n",
    "            FLAGS.train_data, FLAGS.epochs_per_eval, True, FLAGS.batch_size))\n",
    "\n",
    "        results = model.evaluate(input_fn=lambda: input_fn(\n",
    "            FLAGS.test_data, 1, False, FLAGS.batch_size))\n",
    "\n",
    "        # Display evaluation metrics\n",
    "        print('Results at epoch', (n + 1) * FLAGS.epochs_per_eval)\n",
    "        print('-' * 60)\n",
    "\n",
    "    for key in sorted(results):\n",
    "        print('%s: %s' % (key, results[key]))\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
